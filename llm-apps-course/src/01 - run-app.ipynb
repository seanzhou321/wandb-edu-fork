{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6bf2b96a-1c54-4f60-a839-d347cae521cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: sean-zhou321 (sean-zhou321-SELF). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\yixio\\github\\wandb\\edu\\llm-apps-course\\src\\wandb\\run-20240909_161224-eogg84fb</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sean-zhou321-SELF/llmapps/runs/eogg84fb' target=\"_blank\">graceful-snowball-10</a></strong> to <a href='https://wandb.ai/sean-zhou321-SELF/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sean-zhou321-SELF/llmapps' target=\"_blank\">https://wandb.ai/sean-zhou321-SELF/llmapps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sean-zhou321-SELF/llmapps/runs/eogg84fb' target=\"_blank\">https://wandb.ai/sean-zhou321-SELF/llmapps/runs/eogg84fb</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yixio\\github\\wandb\\edu\\llm-apps-course\\src\\ingest.py:84: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  vector_store.persist()\n",
      "wandb: Adding directory to artifact (.\\..\\vector_store)... Done. 0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 59.2%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">graceful-snowball-10</strong> at: <a href='https://wandb.ai/sean-zhou321-SELF/llmapps/runs/eogg84fb' target=\"_blank\">https://wandb.ai/sean-zhou321-SELF/llmapps/runs/eogg84fb</a><br/> View project at: <a href='https://wandb.ai/sean-zhou321-SELF/llmapps' target=\"_blank\">https://wandb.ai/sean-zhou321-SELF/llmapps</a><br/>Synced 5 W&B file(s), 0 media file(s), 7 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240909_161224-eogg84fb\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run ingest.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fba527b4-f571-449b-91ba-d658f472a9f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: sean-zhou321 (sean-zhou321-SELF). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.9"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\yixio\\github\\wandb\\edu\\llm-apps-course\\src\\wandb\\run-20240909_204552-r8t7ij4j</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sean-zhou321-SELF/llmapps/runs/r8t7ij4j' target=\"_blank\">vivid-morning-17</a></strong> to <a href='https://wandb.ai/sean-zhou321-SELF/llmapps' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sean-zhou321-SELF/llmapps' target=\"_blank\">https://wandb.ai/sean-zhou321-SELF/llmapps</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sean-zhou321-SELF/llmapps/runs/r8t7ij4j' target=\"_blank\">https://wandb.ai/sean-zhou321-SELF/llmapps/runs/r8t7ij4j</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sean-zhou321-SELF/llmapps/generated_examples:latest\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   1 of 1 files downloaded.  \n",
      "wandb:   5 of 5 files downloaded.  \n",
      "wandb:   1 of 1 files downloaded.  \n",
      "  0%|                                                                                           | 0/55 [00:00<?, ?it/s]C:\\Users\\yixio\\github\\wandb\\edu\\llm-apps-course\\src\\eval.py:47: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use invoke instead.\n",
      "  result = qa_chain({\"question\": query, \"chat_history\": []})\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 55/55 [02:35<00:00,  2.83s/it]\n",
      "No human prompt provided. Using default human prompt from prompts\n",
      "C:\\Users\\yixio\\github\\wandb\\edu\\llm-apps-course\\src\\eval.py:66: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 0.9%"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>model_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>model_accuracy</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vivid-morning-17</strong> at: <a href='https://wandb.ai/sean-zhou321-SELF/llmapps/runs/r8t7ij4j' target=\"_blank\">https://wandb.ai/sean-zhou321-SELF/llmapps/runs/r8t7ij4j</a><br/> View project at: <a href='https://wandb.ai/sean-zhou321-SELF/llmapps' target=\"_blank\">https://wandb.ai/sean-zhou321-SELF/llmapps</a><br/>Synced 5 W&B file(s), 1 media file(s), 4 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240909_204552-r8t7ij4j\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run eval.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4f2452d-662e-457c-b88e-86b584cf055b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import eval as this_eval\n",
    "from config import default_config\n",
    "from prompts import load_eval_prompt\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import StrOutputParser\n",
    "\n",
    "import pandas as pd\n",
    "eval_dataset = pd.read_csv(\"eval_with_answers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e96c17da-c157-4584-a87c-cff2983d5002",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No human prompt provided. Using default human prompt from prompts\n"
     ]
    }
   ],
   "source": [
    "eval_prompt = load_eval_prompt()\n",
    "llm = ChatOpenAI(\n",
    "    model_name=default_config.eval_model,\n",
    "    temperature=0,\n",
    ")\n",
    "chain = prompt | llm | StrOutputParser()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354dab0-2889-41f4-bf71-95ba80684571",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.evaluation import load_evaluator, EvaluatorType, Criteria\n",
    "evaluator = load_evaluator(evaluator=EvaluatorType.LABELED_CRITERIA, llm=llm, criteria=Criteria.CORRECTNESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9266307-ec84-4db6-929f-a356c0ef909a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criteria = {\n",
    "    \"relevance\": \"Is the response relevant to the question?\",\n",
    "    \"coherence\": \"Is the response coherent and well-structured?\",\n",
    "    \"accuracy\": \"Does the response contain accurate information?\",\n",
    "}\n",
    "eval_chain = {\"query\": lambda x: x[\"topic\"], \"output\": chain} | load_evaluator(\"criteria\", criteria=criteria)\n",
    "\n",
    "result = eval_chain.invoke(\n",
    "    prediction=eval_dataset[\"model_answer\"].iloc[i], \n",
    "    reference=eval_dataset[\"answer\"].iloc[i], \n",
    "    input=eval_dataset[\"question\"].iloc[i]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7b85c3c9-3584-4167-a7f5-fa1d09be9477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an evaluator\n",
    "evaluator = load_evaluator(\"criteria\", criteria=\"humor\")\n",
    "\n",
    "# Combine chain and evaluator\n",
    "eval_chain = {\"input\": lambda x: x[\"topic\"], \"output\": chain} | evaluator\n",
    "\n",
    "i=0\n",
    "examples=[{\n",
    "    \"query\": eval_dataset[\"question\"].iloc[i],\n",
    "    \"answer\": eval_dataset[\"answer\"].iloc[i],\n",
    "}]\n",
    "predictions=[{\n",
    "    \"query\": eval_dataset[\"question\"].iloc[i],\n",
    "    \"answer\": eval_dataset[\"answer\"].iloc[i],\n",
    "    \"result\": eval_dataset[\"model_answer\"].iloc[i],\n",
    "}]\n",
    "\n",
    "evaluator = LabeledCriteriaEvalChain.from_llm(llm=llm, criteria=criteria)\n",
    "\n",
    "result = evaluator.evaluate_strings(\n",
    "    prediction=eval_dataset[\"model_answer\"].iloc[i], \n",
    "    reference=eval_dataset[\"answer\"].iloc[i], \n",
    "    input=eval_dataset[\"question\"].iloc[i]\n",
    ")\n",
    "\n",
    "# graded_outputs = eval_chain.evaluate(examples, predictions)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
